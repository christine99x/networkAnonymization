{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdaf88bb",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e56ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import random\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb11110",
   "metadata": {},
   "source": [
    "# Common part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2d667",
   "metadata": {},
   "source": [
    "## Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e062595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compuate equivalent class.\n",
    "def ig_to_nauty(g):\n",
    "    graph = \"n \" + str(g.vcount()) + \"\\n\"\n",
    "    graph += \"g\\n\"\n",
    "    for n in g.vs.indices:\n",
    "        graph += str(n) + \":\"\n",
    "        for m in g.neighbors(n):\n",
    "            graph += \" \" + str(m)\n",
    "        graph += \";\\n\"\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def computeEQ(G, criteria='dk'):\n",
    "    '''\n",
    "    Input: orignal graph\n",
    "    Output: a dict of equivalent class and the list of nodes of the eqvialent class. i.e. {'class id': [nodes]}\n",
    "    '''\n",
    "    P = defaultdict(list)\n",
    "    if criteria == 'dk':\n",
    "        ng = ig_to_nauty(G)\n",
    "        cmd = ng + \"d \" + str(1) + \"\\na\\n\"\n",
    "        cmd += \".\\n\"\n",
    "        r = subprocess.Popen(['./dkAnonymity/src/menu'], \n",
    "                            stdin=subprocess.PIPE, \n",
    "                            stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.PIPE, \n",
    "                            shell=True)\n",
    "        res = r.communicate(cmd.encode())[0].decode()\n",
    "        str_p = res.split(\"\\n\")\n",
    "        str_p = str_p[str_p.index(\"node, class_id\")+1: str_p.index(\"End eq map\")]\n",
    "\n",
    "        for i in str_p:\n",
    "            p = i.split(\", \")\n",
    "            P[p[1]].append(int(p[0]))\n",
    "    \n",
    "    elif criteria == 'nm':\n",
    "        for node in G.vs.indices:\n",
    "            neighborhood = G.neighbors(node)\n",
    "            n = len(neighborhood) + 1\n",
    "            neighborhood.append(node)\n",
    "            sg = G.subgraph(neighborhood)\n",
    "            m = sg.ecount()\n",
    "            P[(n, m)].append(node)\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d937a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the uniqueness of the network.\n",
    "def uniqueness(G, criteria):\n",
    "    '''\n",
    "    Input: original graph\n",
    "    Output: a number of uniquendess, and a list of unique nodes\n",
    "    '''\n",
    "    u = 0\n",
    "    n = G.vcount()\n",
    "    p = computeEQ(G, criteria)\n",
    "    unique_nodes = set()\n",
    "    for cl in p:\n",
    "        if len(p[cl]) < 2:\n",
    "            u += 1/n\n",
    "            unique_nodes.update(p[cl])\n",
    "    \n",
    "    return u, unique_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37e8f3",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5837a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 800 6429 -- \n",
      "+ attr: _nx_name (v)\n",
      "ACC: 0.3153509697401216 Transitivity: 0.24430902767456378\n",
      "U_nm: 0.8174999999999881\n"
     ]
    }
   ],
   "source": [
    "G_origin = nx.Graph()\n",
    "# read data\n",
    "\n",
    "# copenet-sms\n",
    "# with open('sms.csv', newline='') as f:\n",
    "#     lines = csv.reader(f, delimiter=',')\n",
    "#     for line in lines:\n",
    "#         G_origin.add_edge(line[1], line[2])\n",
    "\n",
    "# copenet-fb\n",
    "with open('fb_friends.csv', newline='') as f:\n",
    "    lines = csv.reader(f, delimiter=',')\n",
    "    for line in lines:\n",
    "        G_origin.add_edge(line[0], line[1])\n",
    "\n",
    "# # CollegeMsg\n",
    "# with open('CollegeMsg.txt') as f:\n",
    "#         for line in f:\n",
    "#             edge = line.strip().split(' ')\n",
    "#             G_origin.add_edge(edge[0], edge[1])\n",
    "\n",
    "# ca-grqc        \n",
    "# with open('CA-GrQc.txt') as f:\n",
    "#         for line in f:\n",
    "#             edge = line.strip().split('\\t')\n",
    "#             G_origin.add_edge(edge[0], edge[1])\n",
    "\n",
    "# ego-fb\n",
    "# with open('facebook_combined.txt') as f:\n",
    "#         for line in f:\n",
    "#             edge = line.strip().split(' ')\n",
    "#             G_origin.add_edge(edge[0], edge[1])\n",
    "\n",
    "G_origin = ig.Graph.from_networkx(G_origin)\n",
    "U, unodes_origin = uniqueness(G_origin, 'dk')\n",
    "# print(unodes_origin)\n",
    "\n",
    "# info of empirical network\n",
    "ig.summary(G_origin)\n",
    "print(\"ACC:\", G_origin.transitivity_avglocal_undirected(mode=\"zero\"), \"Transitivity:\", G_origin.transitivity_undirected())\n",
    "print(\"U_nm:\", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b479a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "STEP = 144\n",
    "# CALCULATE_TIME = G_origin.ecount() // STEP\n",
    "CALCULATE_TIME = 100\n",
    "\n",
    "x = list(range(STEP, (CALCULATE_TIME+1)*STEP, STEP))\n",
    "u_of_10 = np.full((10, CALCULATE_TIME+1), U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b53dd6",
   "metadata": {},
   "source": [
    "# Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e537ee",
   "metadata": {},
   "source": [
    "## Random Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60a2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random deletion\n",
    "def randomDelete(G, num):\n",
    "    edges = random.sample(G.es.indices, num)\n",
    "    G.delete_edges(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e7d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random1Round(G, U, STEP, CALCULATE_TIME, criteria):\n",
    "    u_random = [U]\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # random delete\n",
    "        G = randomDelete(G, STEP)\n",
    "        new_u_random, _ = uniqueness(G, criteria)\n",
    "        u_random.append(new_u_random)\n",
    "    #     print(\"u_random:\", new_u_random)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_random, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00b3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of random delete: 5.651s\n"
     ]
    }
   ],
   "source": [
    "G_random = G_origin.copy()\n",
    "\n",
    "u_random, t_random = random1Round(G_random, U, STEP, CALCULATE_TIME, 'nm')\n",
    "print('Time of random delete: {:.3f}s'.format(t_random))\n",
    "\n",
    "with open('./imtermediate results/RandomNM.txt', 'wb') as f:\n",
    "    pickle.dump(u_random, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18957a8a",
   "metadata": {},
   "source": [
    "## Max-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bd1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all edges between unique nodes.\n",
    "def getEdgeListUnique(G, node_list):\n",
    "    '''\n",
    "    Input: original graph, and list of unique nodes\n",
    "    Output: list of edges between unique nodes\n",
    "    '''\n",
    "    edges = G.get_edgelist()\n",
    "    res = []\n",
    "    for edge in edges:\n",
    "        if (edge[0] in node_list) and (edge[1] in node_list):\n",
    "            res.append(edge)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c753445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete edges based on the maximum degrees of the connected nodes.\n",
    "def deleteMax(G, num, edge_list):\n",
    "    '''\n",
    "    Input: \n",
    "        G: original graph, \n",
    "        num: number of edges need to be deleted, \n",
    "        edges_list: list edges that only touch the unique nodes.\n",
    "    Output: modified graph\n",
    "    '''\n",
    "    p = []\n",
    "    edges = []\n",
    "    if num < len(edge_list):    # if the edges between unique nodes are enough\n",
    "        edge_candidates = edge_list.copy()\n",
    "    else:\n",
    "        edge_candidates = G.get_edgelist()\n",
    "    \n",
    "    for j in edge_candidates:\n",
    "        nodes_deg = 1/max(G.degree(j[0]), G.degree(j[1]))\n",
    "        p.append(nodes_deg)\n",
    "    for _ in range(num):\n",
    "        edge = random.choices(edge_candidates, weights=tuple(p))[0]\n",
    "        index = edge_candidates.index(edge)\n",
    "        edges.append(G.get_eid(edge[0], edge[1]))\n",
    "        p[index] = 0\n",
    "    \n",
    "    G.delete_edges(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b83bcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max1Round(G, U, edge_list, STEP, CALCULATE_TIME, criteria):\n",
    "    u_max = [U]\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # delete-max\n",
    "        G = deleteMax(G, STEP, edge_list)\n",
    "        # update info of delete-max\n",
    "        new_u_max, unodes_max = uniqueness(G, criteria)\n",
    "        u_max.append(new_u_max)\n",
    "        edge_list = getEdgeListUnique(G, unodes_max)\n",
    "    #     print(\"u_max:\", new_u_max)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_max, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ccfcabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of delete-max: 11.823s\n"
     ]
    }
   ],
   "source": [
    "G_max = G_origin.copy()\n",
    "edge_list = getEdgeListUnique(G_origin, unodes_origin)\n",
    "\n",
    "u_max, t_max = max1Round(G_max, U, edge_list, STEP, CALCULATE_TIME, 'nm')\n",
    "print('Time of delete-max: {:.3f}s'.format(t_max))\n",
    "\n",
    "with open('./imtermediate results/MaxNM.txt', 'wb') as f:\n",
    "    pickle.dump(u_max, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4cd507",
   "metadata": {},
   "source": [
    "## U/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f409bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the U and A of all edges.\n",
    "def edgeUA(G, unodes):\n",
    "    '''\n",
    "    Input: original graph, and list of unique nodes\n",
    "    Output: U, A, and directly connected unique nodes\n",
    "    '''\n",
    "    edges = G.get_edgelist()\n",
    "    res = {}\n",
    "    for u, v in edges:\n",
    "        f = []\n",
    "        node_list = [u, v]\n",
    "        neighbors_u = set(G.neighbors(u))\n",
    "        neighbors_v = set(G.neighbors(v))\n",
    "        node_list += list(neighbors_u.intersection(neighbors_v))\n",
    "        for node in node_list:\n",
    "            if node in unodes:\n",
    "                f.append(1)\n",
    "            else:\n",
    "                f.append(0)\n",
    "        res[u,v] = (sum(f), len(f)-sum(f), f[0]+f[1])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b5d5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete edges based on U/A\n",
    "def deleteUA(G, num, ua):\n",
    "    '''\n",
    "    Input:\n",
    "        G: original graph\n",
    "        num: number of edges need to be deleted\n",
    "        ua: U, A, number of directly connected unique nodes\n",
    "    Output: modified graph\n",
    "    '''\n",
    "    p = []\n",
    "    edges = []\n",
    "    edge_candidates = G.get_edgelist()\n",
    "    for j in edge_candidates:\n",
    "        p.append((ua[j][0]+0.01)/(ua[j][1]+0.01))\n",
    "    for _ in range(num):\n",
    "        edge = random.choices(edge_candidates, weights=tuple(p))[0]\n",
    "        index = edge_candidates.index(edge)\n",
    "        edges.append(G.get_eid(edge[0], edge[1]))\n",
    "        p[index] = 0\n",
    "\n",
    "    G.delete_edges(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b248f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UA1Round(G, U, edge_vec, STEP, CALCULATE_TIME, criteria):\n",
    "    u_ua = [U]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # delete-U/A\n",
    "        G = deleteUA(G, STEP, edge_vec)\n",
    "        new_u_ua, unodes_ua = uniqueness(G, criteria)\n",
    "        u_ua.append(new_u_ua)\n",
    "        edge_vec = edgeUA(G, unodes_ua)\n",
    "    #     print(\"u_ua:\", new_u_ua)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_ua, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23f5d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of delete-U/A: 94.756s\n"
     ]
    }
   ],
   "source": [
    "G_ua = G_origin.copy()\n",
    "edge_vec = edgeUA(G_origin, unodes_origin)\n",
    "\n",
    "u_ua, t_ua = UA1Round(G_ua, U, edge_vec, STEP, CALCULATE_TIME, 'dk')\n",
    "print('Time of delete-U/A: {:.3f}s'.format(t_ua))\n",
    "\n",
    "with open('./imtermediate results/UANM.txt', 'wb') as f:\n",
    "    pickle.dump(u_ua, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192855da",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838778d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer effect of uniqueness to label.\n",
    "def value2label(x):\n",
    "    if x>=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36661314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete edges based on Logistic Regression Classification.\n",
    "def LRDelete(G, num, model, unodes):\n",
    "    '''\n",
    "    Input:\n",
    "        G: original graph\n",
    "        num: the number of edges need to be deleted\n",
    "        model: the trained classifier\n",
    "        unodes: list of unique nodes\n",
    "    Output: modified graph\n",
    "    '''\n",
    "    edges = G.get_edgelist()\n",
    "    edge_vector = edgeUA(G, unodes)\n",
    "    n = G.vcount()\n",
    "    m = G.ecount()\n",
    "    df = pd.DataFrame(columns=['N_nodes', 'N_edges', 'max', 'min', 'U', 'A', 'direct_connected_nodes', 'triangles'])\n",
    "    for e in edges:\n",
    "        df.loc[G.get_eid(e[0], e[1]), :] = [n, m, max(G.degree(e[0]), G.degree(e[1])), min(G.degree(e[0]), G.degree(e[1])), \n",
    "                                edge_vector[e][0], edge_vector[e][1], edge_vector[e][2], edge_vector[e][0]+edge_vector[e][1]-2]\n",
    "    p = model.predict_proba(df)\n",
    "    p = p[:,1]\n",
    "    index = np.argsort(p)[-num:]\n",
    "    G.delete_edges([G.get_eid(edges[i][0], edges[i][1]) for i in index])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a317f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014892239385811\n",
      "Coef: [ 7.92286457e-04 -3.18002565e-04 -3.42318006e-02 -1.79193509e-01\n",
      "  2.18984327e-02 -6.41586529e-03  1.86520047e+00  1.07835186e-01]\n"
     ]
    }
   ],
   "source": [
    "# train LR model\n",
    "train = pd.read_csv('training_data.csv', index_col=0)\n",
    "train['eff'] = train['eff'].apply(lambda x: value2label(x))\n",
    "classifier = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "classifier.fit(train.iloc[:, :8], train.iloc[:, 8])\n",
    "print(classifier.score(train.iloc[:, :8], train.iloc[:, 8]))\n",
    "print(\"Coef:\", classifier.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b4961",
   "metadata": {},
   "source": [
    "P-value for LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b39412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99995696 0.         0.         0.         0.         0.99999904\n",
      " 0.99999972 0.         0.99999526]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def logit_pvalue(model, x):\n",
    "    p = model.predict_proba(x)\n",
    "    n = len(p)\n",
    "    m = len(model.coef_[0]) + 1\n",
    "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
    "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
    "    ans = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
    "    vcov = np.linalg.inv(np.matrix(ans))\n",
    "    se = np.sqrt(np.diag(vcov))\n",
    "    t =  coefs/se  \n",
    "    p = (1 - norm.cdf(abs(t))) * 2\n",
    "    return p\n",
    "\n",
    "\n",
    "print(logit_pvalue(classifier, train.iloc[:, :8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85491c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR1Round(G, U, unodes_origin, STEP, CALCULATE_TIME, criteria):\n",
    "    u_lr = [U]\n",
    "    unodes = unodes_origin.copy()\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # delete-LR\n",
    "        G = LRDelete(G, STEP, classifier, unodes)\n",
    "        # update info of delete-ua\n",
    "        new_u_lr, unodes = uniqueness(G, criteria)\n",
    "        u_lr.append(new_u_lr)\n",
    "    #     print(\"u_lr:\", new_u_lr)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_lr, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8036ef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of LR: 303.260s\n"
     ]
    }
   ],
   "source": [
    "G_lr = G_origin.copy()\n",
    "\n",
    "u_lr, t_lr = LR1Round(G_lr, U, unodes_origin, STEP, CALCULATE_TIME, 'nm')\n",
    "print('Time of LR: {:.3f}s'.format(t_lr))\n",
    "\n",
    "# with open('./imtermediate results/LRNM.txt', 'wb') as f:\n",
    "#     pickle.dump(u_lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32312956",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6a88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeVector(G):\n",
    "    res = {}\n",
    "    for node in G.vs.indices:\n",
    "        neighborhood = G.neighbors(node)\n",
    "        neighborhood.append(node)\n",
    "        sg = G.subgraph(neighborhood)    # ego network\n",
    "        res[node] = [len(neighborhood), sg.ecount()]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def delEdgeEff(G, edge, node_vec):\n",
    "    eff = 0\n",
    "    common_neighbors = set(G.neighbors(edge[0])).intersection(set(G.neighbors(edge[1])))\n",
    "    P = Counter([tuple(node_vec[i]) for i in node_vec])\n",
    "    \n",
    "    for node in common_neighbors:    # indirectly related nodes\n",
    "        n, m = tuple(node_vec[node])\n",
    "        P[(n,m)] -= 1\n",
    "        if P[(n,m)] == 1: eff -= 1\n",
    "        elif P[(n,m)] == 0: eff += 1\n",
    "        m -= 1\n",
    "        if (n, m) not in P: eff -= 1\n",
    "        elif P[(n,m)] == 1: eff += 1\n",
    "        P[(n,m)] += 1\n",
    "\n",
    "    # directly related nodes\n",
    "    n, m = tuple(node_vec[edge[0]])\n",
    "    P[(n,m)] -= 1\n",
    "    if P[(n,m)] == 1: eff -= 1\n",
    "    elif P[(n,m)] == 0: eff += 1\n",
    "\n",
    "    n -= 1\n",
    "    m -= len(common_neighbors)+1\n",
    "    if (n, m) not in P: eff -= 1\n",
    "    elif P[(n,m)] == 1: eff += 1\n",
    "    P[(n,m)] += 1\n",
    "    \n",
    "    n, m = tuple(node_vec[edge[1]])\n",
    "    P[tuple(node_vec[edge[1]])] -= 1\n",
    "    if P[(n,m)] == 1: eff -= 1\n",
    "    elif P[(n,m)] == 0: eff += 1\n",
    "    \n",
    "    n -= 1\n",
    "    m -= len(common_neighbors)+1\n",
    "    if (n, m) not in P: eff -= 1\n",
    "    elif P[(n,m)] == 1: eff += 1\n",
    "    P[(n,m)] += 1\n",
    "\n",
    "    return eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93bf5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyDelete(G, num, node_vec=None):\n",
    "    edges = G.get_edgelist()\n",
    "    if not node_vec:\n",
    "        node_vec = getNodeVector(G)\n",
    "    values = []\n",
    "    \n",
    "    for edge in edges:\n",
    "        values.append(delEdgeEff(G, edge, node_vec))\n",
    "    sorted_edges = sorted([i for i in enumerate(values)], key=lambda x: x[1])[-num:]\n",
    "    G.delete_edges([G.get_eid(edges[i[0]][0], edges[i[0]][1]) for i in sorted_edges])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625a1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy1Round(G, U, STEP, CALCULATE_TIME, criteria):\n",
    "    u = [U]\n",
    "    t_u = t_d = 0\n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        G = greedyDelete(G, STEP)\n",
    "        new_u, _ = uniqueness(G, criteria)\n",
    "        u.append(new_u)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u, t1-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d1e96",
   "metadata": {},
   "source": [
    "# 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e61dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 638.086s\n"
     ]
    }
   ],
   "source": [
    "T = 0\n",
    "for t in range(10):\n",
    "    G = G_origin.copy()\n",
    "#     edge_list = getEdgeListUnique(G_origin, unodes_origin)\n",
    "#     edge_vec = edgeUA(G_origin, unodes_origin)\n",
    "    new_u, runtime = greedy1Round(G, U, STEP, CALCULATE_TIME, 'dk')\n",
    "    u_of_10[t] = new_u\n",
    "    T += runtime\n",
    "print(\"Average time: {:.3f}s\".format(T/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfb5abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./intermediate results/greedy-egoFB-10-NM-882STEP.txt', 'wb') as f:\n",
    "    pickle.dump(u_of_10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb99d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    u_of_10[i] = u_of_10[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83825f43",
   "metadata": {},
   "source": [
    "# Delete 1% edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "e4bedb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13506295307134755\n",
      "Uniqueness: 0.116\n",
      "ACC: 0.520\n",
      "T: 0.629\n",
      "Time: 39.204s\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "STEP = 25\n",
    "CALCULATE_TIME = G_origin.ecount() // 100 // STEP\n",
    "U, unodes_origin = uniqueness(G_origin, 'dk')\n",
    "print(U)\n",
    "\n",
    "x = list(range(STEP, (CALCULATE_TIME+1)*STEP, STEP))\n",
    "u_of_10 = np.full((10, CALCULATE_TIME+1), U)\n",
    "\n",
    "u_sum = 0\n",
    "a_sum = 0\n",
    "t_sum = 0\n",
    "\n",
    "T = 0\n",
    "t0 = time.time()\n",
    "for t in range(1):\n",
    "    G = G_origin.copy()\n",
    "#     edge_list = getEdgeListUnique(G_origin, unodes_origin)\n",
    "#     edge_vec = edgeUA(G_origin, unodes_origin)\n",
    "    new_u, _, _ = LR1Round(G, U, unodes_origin, STEP, CALCULATE_TIME, 'dk')\n",
    "    a_sum += G.transitivity_avglocal_undirected(mode=\"zero\")\n",
    "    t_sum += G.transitivity_undirected()\n",
    "    u_sum += new_u[-1]\n",
    "t1 = time.time()\n",
    "print(\"Uniqueness: {:.3f}\".format(u_sum/1))\n",
    "print(\"ACC: {:.3f}\".format(a_sum/1))\n",
    "print(\"T: {:.3f}\".format(t_sum/1))\n",
    "print(\"Time: {:.3f}s\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc03d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
