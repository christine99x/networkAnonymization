{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdaf88bb",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e56ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import random\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb11110",
   "metadata": {},
   "source": [
    "# Common part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2d667",
   "metadata": {},
   "source": [
    "## Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e062595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compuate equivalent class.\n",
    "def ig_to_nauty(g):\n",
    "    graph = \"n \" + str(g.vcount()) + \"\\n\"\n",
    "    graph += \"g\\n\"\n",
    "    for n in g.vs.indices:\n",
    "        graph += str(n) + \":\"\n",
    "        for m in g.neighbors(n):\n",
    "            graph += \" \" + str(m)\n",
    "        graph += \";\\n\"\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def computeEQ(G, criteria='dk'):\n",
    "    '''\n",
    "    Input: orignal graph\n",
    "    Output: a dict of equivalent class and the list of nodes of the eqvialent class. i.e. {'class id': [nodes]}\n",
    "    '''\n",
    "    P = defaultdict(list)\n",
    "    if criteria == 'dk':\n",
    "        ng = ig_to_nauty(G)\n",
    "        cmd = ng + \"d \" + str(1) + \"\\na\\n\"\n",
    "        cmd += \".\\n\"\n",
    "        r = subprocess.Popen(['./dkAnonymity/src/menu'], \n",
    "                            stdin=subprocess.PIPE, \n",
    "                            stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.PIPE, \n",
    "                            shell=True)\n",
    "        res = r.communicate(cmd.encode())[0].decode()\n",
    "        str_p = res.split(\"\\n\")\n",
    "        str_p = str_p[str_p.index(\"node, class_id\")+1: str_p.index(\"End eq map\")]\n",
    "\n",
    "        for i in str_p:\n",
    "            p = i.split(\", \")\n",
    "            P[p[1]].append(int(p[0]))\n",
    "    \n",
    "    elif criteria == 'nm':\n",
    "        for node in G.vs.indices:\n",
    "            neighborhood = G.neighbors(node)\n",
    "            n = len(neighborhood) + 1\n",
    "            neighborhood.append(node)\n",
    "            sg = G.subgraph(neighborhood)\n",
    "            m = sg.ecount()\n",
    "            P[(n, m)].append(node)\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d937a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the uniqueness of the network.\n",
    "def uniqueness(G, criteria):\n",
    "    '''\n",
    "    Input: original graph\n",
    "    Output: a number of uniquendess, and a list of unique nodes\n",
    "    '''\n",
    "    u = 0\n",
    "    n = G.vcount()\n",
    "    p = computeEQ(G, criteria)\n",
    "    unique_nodes = set()\n",
    "    for cl in p:\n",
    "        if len(p[cl]) < 2:\n",
    "            u += 1/n\n",
    "            unique_nodes.update(p[cl])\n",
    "    \n",
    "    return u, unique_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37e8f3",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f5837a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 5242 14496 -- \n",
      "+ attr: _nx_name (v)\n",
      "ACC: 0.529635811052136 Transitivity: 0.6298424741263426\n",
      "U_nm: 0.13506295307134755\n"
     ]
    }
   ],
   "source": [
    "G_origin = nx.Graph()\n",
    "# read data\n",
    "\n",
    "# copenet-sms\n",
    "# with open('sms.csv', newline='') as f:\n",
    "#     lines = csv.reader(f, delimiter=',')\n",
    "#     for line in lines:\n",
    "#         G_origin.add_edge(line[1], line[2])\n",
    "\n",
    "# copenet-fb\n",
    "# with open('fb_friends.csv', newline='') as f:\n",
    "#     lines = csv.reader(f, delimiter=',')\n",
    "#     for line in lines:\n",
    "#         G_origin.add_edge(line[0], line[1])\n",
    "\n",
    "# # CollegeMsg\n",
    "# with open('CollegeMsg.txt') as f:\n",
    "#         for line in f:\n",
    "#             edge = line.strip().split(' ')\n",
    "#             G_origin.add_edge(edge[0], edge[1])\n",
    "\n",
    "# ca-grqc        \n",
    "with open('CA-GrQc.txt') as f:\n",
    "        for line in f:\n",
    "            edge = line.strip().split('\\t')\n",
    "            G_origin.add_edge(edge[0], edge[1])\n",
    "\n",
    "# ego-fb\n",
    "# with open('facebook_combined.txt') as f:\n",
    "#         for line in f:\n",
    "#             edge = line.strip().split(' ')\n",
    "#             G_origin.add_edge(edge[0], edge[1])\n",
    "\n",
    "G_origin = ig.Graph.from_networkx(G_origin)\n",
    "U, unodes_origin = uniqueness(G_origin, 'dk')\n",
    "# print(unodes_origin)\n",
    "\n",
    "# info of empirical network\n",
    "ig.summary(G_origin)\n",
    "print(\"ACC:\", G_origin.transitivity_avglocal_undirected(mode=\"zero\"), \"Transitivity:\", G_origin.transitivity_undirected())\n",
    "print(\"U_nm:\", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b479a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "STEP = 25\n",
    "CALCULATE_TIME = G_origin.ecount() // STEP\n",
    "\n",
    "x = list(range(STEP, (CALCULATE_TIME+1)*STEP, STEP))\n",
    "u_of_10 = np.full((10, CALCULATE_TIME+1), U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b53dd6",
   "metadata": {},
   "source": [
    "# Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e537ee",
   "metadata": {},
   "source": [
    "## Random Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d60a2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random deletion\n",
    "def randomDelete(G, num):\n",
    "    edges = random.sample(G.es.indices, num)\n",
    "    G.delete_edges(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "14e7d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random1Round(G, U, STEP, CALCULATE_TIME, criteria):\n",
    "    u_random = [U]\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # random delete\n",
    "        G = randomDelete(G, STEP)\n",
    "        new_u_random, _ = uniqueness(G, criteria)\n",
    "        u_random.append(new_u_random)\n",
    "    #     print(\"u_random:\", new_u_random)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_random, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c00b3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of random delete: 8.931s\n"
     ]
    }
   ],
   "source": [
    "G_random = G_origin.copy()\n",
    "\n",
    "u_random, t_random = random1Round(G_random, U, STEP, CALCULATE_TIME, 'nm')\n",
    "print('Time of random delete: {:.3f}s'.format(t_random))\n",
    "\n",
    "with open('./imtermediate results/RandomNM.txt', 'wb') as f:\n",
    "    pickle.dump(u_random, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18957a8a",
   "metadata": {},
   "source": [
    "## Max-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48bd1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all edges between unique nodes.\n",
    "def getEdgeListUnique(G, node_list):\n",
    "    '''\n",
    "    Input: original graph, and list of unique nodes\n",
    "    Output: list of edges between unique nodes\n",
    "    '''\n",
    "    edges = G.get_edgelist()\n",
    "    res = []\n",
    "    for edge in edges:\n",
    "        if (edge[0] in node_list) and (edge[1] in node_list):\n",
    "            res.append(edge)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5c753445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete edges based on the maximum degrees of the connected nodes.\n",
    "def deleteMax(G, num, edge_list):\n",
    "    '''\n",
    "    Input: \n",
    "        G: original graph, \n",
    "        num: number of edges need to be deleted, \n",
    "        edges_list: list edges that only touch the unique nodes.\n",
    "    Output: modified graph\n",
    "    '''\n",
    "    p = []\n",
    "    edges = []\n",
    "    if num < len(edge_list):    # if the edges between unique nodes are enough\n",
    "        edge_candidates = edge_list.copy()\n",
    "    else:\n",
    "        edge_candidates = G.get_edgelist()\n",
    "    \n",
    "    for j in edge_candidates:\n",
    "        nodes_deg = 1/max(G.degree(j[0]), G.degree(j[1]))\n",
    "        p.append(nodes_deg)\n",
    "    for _ in range(num):\n",
    "        edge = random.choices(edge_candidates, weights=tuple(p))[0]\n",
    "        index = edge_candidates.index(edge)\n",
    "        edges.append(G.get_eid(edge[0], edge[1]))\n",
    "        p[index] = 0\n",
    "    \n",
    "    G.delete_edges(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b83bcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max1Round(G, U, edge_list, STEP, CALCULATE_TIME, criteria):\n",
    "    u_max = [U]\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # delete-max\n",
    "        G = deleteMax(G, STEP, edge_list)\n",
    "        # update info of delete-max\n",
    "        new_u_max, unodes_max = uniqueness(G, criteria)\n",
    "        u_max.append(new_u_max)\n",
    "        edge_list = getEdgeListUnique(G, unodes_max)\n",
    "    #     print(\"u_max:\", new_u_max)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_max, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ccfcabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of delete-max: 11.823s\n"
     ]
    }
   ],
   "source": [
    "G_max = G_origin.copy()\n",
    "edge_list = getEdgeListUnique(G_origin, unodes_origin)\n",
    "\n",
    "u_max, t_max = max1Round(G_max, U, edge_list, STEP, CALCULATE_TIME, 'nm')\n",
    "print('Time of delete-max: {:.3f}s'.format(t_max))\n",
    "\n",
    "with open('./imtermediate results/MaxNM.txt', 'wb') as f:\n",
    "    pickle.dump(u_max, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4cd507",
   "metadata": {},
   "source": [
    "## U/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f409bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the U and A of all edges.\n",
    "def edgeUA(G, unodes):\n",
    "    '''\n",
    "    Input: original graph, and list of unique nodes\n",
    "    Output: U, A, and directly connected unique nodes\n",
    "    '''\n",
    "    edges = G.get_edgelist()\n",
    "    res = {}\n",
    "    for u, v in edges:\n",
    "        f = []\n",
    "        node_list = [u, v]\n",
    "        neighbors_u = set(G.neighbors(u))\n",
    "        neighbors_v = set(G.neighbors(v))\n",
    "        node_list += list(neighbors_u.intersection(neighbors_v))\n",
    "        for node in node_list:\n",
    "            if node in unodes:\n",
    "                f.append(1)\n",
    "            else:\n",
    "                f.append(0)\n",
    "        res[u,v] = (sum(f), len(f)-sum(f), f[0]+f[1])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b5d5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete edges based on U/A\n",
    "def deleteUA(G, num, ua):\n",
    "    '''\n",
    "    Input:\n",
    "        G: original graph\n",
    "        num: number of edges need to be deleted\n",
    "        ua: U, A, number of directly connected unique nodes\n",
    "    Output: modified graph\n",
    "    '''\n",
    "    p = []\n",
    "    edges = []\n",
    "    edge_candidates = G.get_edgelist()\n",
    "    for j in edge_candidates:\n",
    "        p.append((ua[j][0]+0.01)/(ua[j][1]+0.01))\n",
    "    for _ in range(num):\n",
    "        edge = random.choices(edge_candidates, weights=tuple(p))[0]\n",
    "        index = edge_candidates.index(edge)\n",
    "        edges.append(G.get_eid(edge[0], edge[1]))\n",
    "        p[index] = 0\n",
    "\n",
    "    G.delete_edges(edges)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "26b248f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UA1Round(G, U, edge_vec, STEP, CALCULATE_TIME, criteria):\n",
    "    u_ua = [U]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # delete-U/A\n",
    "        G = deleteUA(G, STEP, edge_vec)\n",
    "        new_u_ua, unodes_ua = uniqueness(G, criteria)\n",
    "        u_ua.append(new_u_ua)\n",
    "        edge_vec = edgeUA(G, unodes_ua)\n",
    "    #     print(\"u_ua:\", new_u_ua)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    return u_ua, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23f5d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of delete-U/A: 94.756s\n"
     ]
    }
   ],
   "source": [
    "G_ua = G_origin.copy()\n",
    "edge_vec = edgeUA(G_origin, unodes_origin)\n",
    "\n",
    "u_ua, t_ua = UA1Round(G_ua, U, edge_vec, STEP, CALCULATE_TIME, 'dk')\n",
    "print('Time of delete-U/A: {:.3f}s'.format(t_ua))\n",
    "\n",
    "with open('./imtermediate results/UANM.txt', 'wb') as f:\n",
    "    pickle.dump(u_ua, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192855da",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "838778d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer effect of uniqueness to label.\n",
    "def value2label(x):\n",
    "    if x>=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36661314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete edges based on Logistic Regression Classification.\n",
    "def LRDelete(G, num, model, unodes):\n",
    "    '''\n",
    "    Input:\n",
    "        G: original graph\n",
    "        num: the number of edges need to be deleted\n",
    "        model: the trained classifier\n",
    "        unodes: list of unique nodes\n",
    "    Output: modified graph\n",
    "    '''\n",
    "    edges = G.get_edgelist()\n",
    "    edge_vector = edgeUA(G, unodes)\n",
    "    n = G.vcount()\n",
    "    m = G.ecount()\n",
    "    df = pd.DataFrame(columns=['N_nodes', 'N_edges', 'max', 'min', 'U', 'A', 'direct_connected_nodes', 'triangles'])\n",
    "    for e in edges:\n",
    "        df.loc[G.get_eid(e[0], e[1]), :] = [n, m, max(G.degree(e[0]), G.degree(e[1])), min(G.degree(e[0]), G.degree(e[1])), \n",
    "                                edge_vector[e][0], edge_vector[e][1], edge_vector[e][2], edge_vector[e][0]+edge_vector[e][1]-2]\n",
    "    p = model.predict_proba(df)\n",
    "    p = p[:,1] - p[:,0]\n",
    "    index = np.argsort(p)[-num:]\n",
    "    G.delete_edges([G.get_eid(edges[i][0], edges[i][1]) for i in index])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a317f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9015755415924224\n",
      "Coef: [ 7.88699707e-04 -3.15945549e-04 -3.43509936e-02 -1.79220651e-01\n",
      "  0.00000000e+00 -2.93035951e-02  1.86289269e+00  1.30494646e-01]\n"
     ]
    }
   ],
   "source": [
    "# train LR model\n",
    "train = pd.read_csv('training_data_2.csv', index_col=0)\n",
    "train['eff'] = train['eff'].apply(lambda x: value2label(x))\n",
    "classifier = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "classifier.fit(train.iloc[:, :8], train.iloc[:, 8])\n",
    "print(classifier.score(train.iloc[:, :8], train.iloc[:, 8]))\n",
    "print(\"Coef:\", classifier.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85491c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR1Round(G, U, unodes_origin, STEP, CALCULATE_TIME, criteria):\n",
    "    u_lr = [U]\n",
    "    unodes = unodes_origin.copy()\n",
    "    t_u = t_d = 0\n",
    "\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        # delete-LR\n",
    "        t0 = time.time()\n",
    "        G = LRDelete(G, STEP, classifier, unodes)\n",
    "        t1 = time.time()\n",
    "        # update info of delete-ua\n",
    "        new_u_lr, unodes = uniqueness(G, criteria)\n",
    "        t2 = time.time()\n",
    "        u_lr.append(new_u_lr)\n",
    "        t_d += t1-t0\n",
    "        t_u += t2-t1\n",
    "    #     print(\"u_lr:\", new_u_lr)\n",
    "    \n",
    "    return u_lr, t_d, t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8036ef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of LR: 707.717s\n"
     ]
    }
   ],
   "source": [
    "G_lr = G_origin.copy()\n",
    "\n",
    "u_lr, t_lr = LR1Round(G_lr, U, STEP, CALCULATE_TIME, 'nm')\n",
    "print('Time of LR: {:.3f}s'.format(t_lr))\n",
    "\n",
    "with open('./imtermediate results/LRNM.txt', 'wb') as f:\n",
    "    pickle.dump(u_lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32312956",
   "metadata": {},
   "source": [
    "## Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d6a88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeVector(G):\n",
    "    res = {}\n",
    "    for node in G.vs.indices:\n",
    "        neighborhood = G.neighbors(node)\n",
    "        neighborhood.append(node)\n",
    "        sg = G.subgraph(neighborhood)    # ego network\n",
    "        res[node] = [len(neighborhood), sg.ecount()]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def delEdgeEff(G, edge, node_vec):\n",
    "    eff = 0\n",
    "    common_neighbors = set(G.neighbors(edge[0])).intersection(set(G.neighbors(edge[1])))\n",
    "    P = Counter([tuple(node_vec[i]) for i in node_vec])\n",
    "    \n",
    "    for node in common_neighbors:    # indirectly related nodes\n",
    "        n, m = tuple(node_vec[node])\n",
    "        P[(n,m)] -= 1\n",
    "        if P[(n,m)] == 1: eff -= 1\n",
    "        elif P[(n,m)] == 0: eff += 1\n",
    "        m -= 1\n",
    "        if (n, m) not in P: eff -= 1\n",
    "        elif P[(n,m)] == 1: eff += 1\n",
    "        P[(n,m)] += 1\n",
    "\n",
    "    # directly related nodes\n",
    "    n, m = tuple(node_vec[edge[0]])\n",
    "    P[(n,m)] -= 1\n",
    "    if P[(n,m)] == 1: eff -= 1\n",
    "    elif P[(n,m)] == 0: eff += 1\n",
    "\n",
    "    n -= 1\n",
    "    m -= len(common_neighbors)+1\n",
    "    if (n, m) not in P: eff -= 1\n",
    "    elif P[(n,m)] == 1: eff += 1\n",
    "    P[(n,m)] += 1\n",
    "    \n",
    "    n, m = tuple(node_vec[edge[1]])\n",
    "    P[tuple(node_vec[edge[1]])] -= 1\n",
    "    if P[(n,m)] == 1: eff -= 1\n",
    "    elif P[(n,m)] == 0: eff += 1\n",
    "    \n",
    "    n -= 1\n",
    "    m -= len(common_neighbors)+1\n",
    "    if (n, m) not in P: eff -= 1\n",
    "    elif P[(n,m)] == 1: eff += 1\n",
    "    P[(n,m)] += 1\n",
    "\n",
    "    return eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93bf5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyDelete(G, num, node_vec=None):\n",
    "    edges = G.get_edgelist()\n",
    "    if not node_vec:\n",
    "        node_vec = getNodeVector(G)\n",
    "    values = []\n",
    "    \n",
    "    for edge in edges:\n",
    "        values.append(delEdgeEff(G, edge, node_vec))\n",
    "    sorted_edges = sorted([i for i in enumerate(values)], key=lambda x: x[1])[-num:]\n",
    "    G.delete_edges([G.get_eid(edges[i[0]][0], edges[i[0]][1]) for i in sorted_edges])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "625a1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy1Round(G, U, STEP, CALCULATE_TIME, criteria):\n",
    "    u = [U]\n",
    "    t_u = t_d = 0\n",
    "    for i in range(CALCULATE_TIME):\n",
    "        t0 = time.time()\n",
    "        G = greedyDelete(G, STEP)\n",
    "        t1 = time.time()\n",
    "        new_u, _ = uniqueness(G, criteria)\n",
    "        t2 = time.time()\n",
    "        u.append(new_u)\n",
    "        t_u += t2-t1\n",
    "        t_d += t1-t0\n",
    "    \n",
    "    return u, t_d, t_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d1e96",
   "metadata": {},
   "source": [
    "# 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9e61dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 1764.153s\n",
      "Average measuring time: 43.520s\n"
     ]
    }
   ],
   "source": [
    "T = 0\n",
    "T_u = 0\n",
    "for t in range(1):\n",
    "    G = G_origin.copy()\n",
    "#     edge_list = getEdgeListUnique(G_origin, unodes_origin)\n",
    "#     edge_vec = edgeUA(G_origin, unodes_origin)\n",
    "    new_u, t_run, t_u = LR1Round(G, U, unodes_origin, STEP, CALCULATE_TIME, 'dk')\n",
    "    u_of_10[t] = new_u\n",
    "    T += t_run\n",
    "    T_u += t_u\n",
    "print(\"Average time: {:.3f}s\".format(T/1))\n",
    "print(\"Average measuring time: {:.3f}s\".format(T_u/1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "bfb5abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./imtermediate results/LR-ca-10-DK-1STEP.txt', 'wb') as f:\n",
    "    pickle.dump(u_of_10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fdb99d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    u_of_10[i] = u_of_10[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83825f43",
   "metadata": {},
   "source": [
    "# Delete 1% edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "e4bedb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13506295307134755\n",
      "Uniqueness: 0.116\n",
      "ACC: 0.520\n",
      "T: 0.629\n",
      "Time: 39.204s\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "STEP = 25\n",
    "CALCULATE_TIME = G_origin.ecount() // 100 // STEP\n",
    "U, unodes_origin = uniqueness(G_origin, 'dk')\n",
    "print(U)\n",
    "\n",
    "x = list(range(STEP, (CALCULATE_TIME+1)*STEP, STEP))\n",
    "u_of_10 = np.full((10, CALCULATE_TIME+1), U)\n",
    "\n",
    "u_sum = 0\n",
    "a_sum = 0\n",
    "t_sum = 0\n",
    "\n",
    "T = 0\n",
    "t0 = time.time()\n",
    "for t in range(1):\n",
    "    G = G_origin.copy()\n",
    "#     edge_list = getEdgeListUnique(G_origin, unodes_origin)\n",
    "#     edge_vec = edgeUA(G_origin, unodes_origin)\n",
    "    new_u, _, _ = LR1Round(G, U, unodes_origin, STEP, CALCULATE_TIME, 'dk')\n",
    "    a_sum += G.transitivity_avglocal_undirected(mode=\"zero\")\n",
    "    t_sum += G.transitivity_undirected()\n",
    "    u_sum += new_u[-1]\n",
    "t1 = time.time()\n",
    "print(\"Uniqueness: {:.3f}\".format(u_sum/1))\n",
    "print(\"ACC: {:.3f}\".format(a_sum/1))\n",
    "print(\"T: {:.3f}\".format(t_sum/1))\n",
    "print(\"Time: {:.3f}s\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88782963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_nauty(input_file, output_file, self_loop=False, debug=True,\n",
    "                 comment=\"%\", sep=\"\\t\", src_col=0, trgt_col=1, skiprows=0, int_type=True):\n",
    "    f_in = open(input_file, \"r\")\n",
    "    f_out = open(output_file, \"w\")\n",
    "    \n",
    "    edge_count = 0\n",
    "    edge_count_undirected = 0\n",
    "    node_dict = {}\n",
    "    edge_list = {}\n",
    "    node_count = 0\n",
    "    self_edges = 0\n",
    "    count = 0\n",
    "    count_mod = 10\n",
    "    skip_count = 0\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Reading \" + str(len(f_in.readlines())) + \" lines from file\")\n",
    "        print(\"Printing data of first 10...\")\n",
    "    f_in = open(input_file, \"r\")\n",
    "    \n",
    "    for ln in f_in:\n",
    "        \n",
    "        if ln.startswith(comment):\n",
    "            continue\n",
    "        if skiprows > skip_count:\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        split = ln.strip().split(sep)\n",
    "        if int_type:\n",
    "            src = int(split[src_col])\n",
    "            trgt = int(split[trgt_col])\n",
    "        else:\n",
    "            src = split[src_col].strip()\n",
    "            trgt = split[trgt_col].strip()\n",
    "            \n",
    "        \n",
    "        # Print first couple of lines\n",
    "        if debug and count < 10:\n",
    "            print(split)\n",
    "        if src == trgt:\n",
    "            if not self_loop:\n",
    "                continue\n",
    "            self_edges += 1\n",
    "        \n",
    "        # Only add nodes with an edge\n",
    "        if src not in node_dict:\n",
    "            node_dict[src] = node_count\n",
    "            node_count += 1\n",
    "        if trgt not in node_dict:\n",
    "            node_dict[trgt] = node_count\n",
    "            node_count += 1\n",
    "        \n",
    "        src = node_dict[src]\n",
    "        trgt = node_dict[trgt]\n",
    "        \n",
    "        try:\n",
    "            edge_list[src].append(trgt)\n",
    "        except:\n",
    "            edge_list[src] = [trgt]\n",
    "        try:\n",
    "            edge_list[trgt].append(src)\n",
    "        except:\n",
    "            edge_list[trgt] = [src]\n",
    "\n",
    "        count+= 1\n",
    "        if debug and count % count_mod == 0:\n",
    "            print(\"Processed edges: \" + str(count))\n",
    "            if count_mod < 100000000:\n",
    "                count_mod *= 10\n",
    "    \n",
    "    # Count edges\n",
    "    for key in edge_list:\n",
    "        edgelist = np.unique(edge_list[key])\n",
    "        edges = len(np.unique(edgelist))\n",
    "        edge_count += edges * 0.5\n",
    "        edge_count_undirected += edges\n",
    "        if key in edgelist:\n",
    "            edge_count += 0.5\n",
    "                \n",
    "    # To nauty format\n",
    "    # Print number of nodes and edges\n",
    "    f_out.write(\"!n=\" + str(len(list(edge_list.keys()))) + \"\\n\")\n",
    "    f_out.write(\"!m=\" + str(edge_count_undirected) + \"\\n\")\n",
    "\n",
    "    # Print edgelist\n",
    "    for s in range(len(list(edge_list.keys()))):\n",
    "        f_out.write(str(s) + \":\")\n",
    "        try:\n",
    "            \n",
    "            targets = np.unique(edge_list[s])\n",
    "            for t in targets:\n",
    "                f_out.write(\" \" + str(t))\n",
    "                \n",
    "            f_out.write(\";\\n\")\n",
    "        except:\n",
    "            f_out.write(\";\\n\")\n",
    "    f_in.close()\n",
    "    f_out.close()\n",
    "    \n",
    "    # Return stats\n",
    "    stats = []\n",
    "    stats.append(len(list(edge_list.keys())))\n",
    "    stats.append(edge_count)\n",
    "    stats.append(self_edges)\n",
    "    return stats\n",
    "    \n",
    "raw_to_nauty(\"CA-GrQc.txt\", \"test\", comment=\"#\", self_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4951ee74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13506295307134755"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "cmd = \"n 5242\\ng\\n\".join(lines)\n",
    "\n",
    "P = defaultdict(list)\n",
    "cmd += \"d \" + str(1) + \"\\na\\n\"\n",
    "cmd += \".\\n\"\n",
    "r = subprocess.Popen(['./dkAnonymity/src/menu'], \n",
    "                            stdin=subprocess.PIPE, \n",
    "                            stdout=subprocess.PIPE, \n",
    "                            stderr=subprocess.PIPE, \n",
    "                            shell=True)\n",
    "res = r.communicate(cmd.encode())[0].decode()\n",
    "str_p = res.split(\"\\n\")\n",
    "str_p = str_p[str_p.index(\"node, class_id\")+1: str_p.index(\"End eq map\")]\n",
    "\n",
    "for i in str_p:\n",
    "    p = i.split(\", \")\n",
    "    P[p[1]].append(int(p[0]))\n",
    "\n",
    "u = 0\n",
    "unique_nodes = []\n",
    "for cl in P:\n",
    "    if len(P[cl]) < 2:\n",
    "        u += 1/5242\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc03d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
